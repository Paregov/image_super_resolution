{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing an image super resolution.\n",
    "## Here I'm going to do some quick training as proof of concept (PoC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from models import generator_no_residual, generator_with_residual, discriminator\n",
    "from utils import check_path_exists\n",
    "from data_loader import load_images_with_truth\n",
    "from loss_functions import perceptual_loss, perceptual_loss_16, perceptual_loss_19\n",
    "from loss_functions import texture_loss_multi_layers, perceptual_plus_texture_loss, perceptual_16_plus_texture_loss\n",
    "from visualizations import plot_images_for_compare, plot_images_for_compare_separate, compare_models, compare_models_single_image\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable this flag if running on the laptop with smaller GPU.\n",
    "running_on_laptop = True\n",
    "\n",
    "# This will use the smaller datasets (train_small, val_small, test_small).\n",
    "use_small_dataset = True\n",
    "\n",
    "# Set to true if you want to use CelebA dataset. Otherwise it will use MS COCO.\n",
    "use_dataset_celeba = False\n",
    "\n",
    "# Set to true and it will not execute training. Usefull when just want to plot the results.\n",
    "disable_training = False\n",
    "\n",
    "# Set to true if you want to load the current weights from the folder before training, so you can\n",
    "# continue with the training\n",
    "load_weights_before_training = False\n",
    "\n",
    "# What to be the verbose level during training.\n",
    "training_verbose = 2\n",
    "\n",
    "enable_p = True\n",
    "enable_p16 = True\n",
    "enable_p19 = True\n",
    "enable_t = True\n",
    "enable_pt = True\n",
    "enable_pt16 = True\n",
    "enable_pt16_bci = True\n",
    "enable_pt_bci = True\n",
    "enable_pt16_no_res = True\n",
    "\n",
    "train_epochs = 100\n",
    "train_batch_size = 32\n",
    "test_image_index_to_show = range(20)\n",
    "optimizer = Adam(lr=0.0001)\n",
    "\n",
    "if running_on_laptop:\n",
    "    train_epochs = 10\n",
    "    train_batch_size = 8\n",
    "    test_image_index_to_show = range(20)\n",
    "    optimizer = Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/MSCOCO/train_small/*\n",
      "./data/MSCOCO/val_small/*\n",
      "./data/MSCOCO/test_small/*\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset path\n",
    "dataset = \"MSCOCO\"\n",
    "if use_dataset_celeba:\n",
    "    dataset = \"celeba\"\n",
    "\n",
    "if not use_small_dataset:\n",
    "    train_dataset_path = './data/{0}/train/*'.format(dataset)\n",
    "    validation_dataset_path = './data/{0}/val/*'.format(dataset)\n",
    "    test_dataset_path = './data/{0}/test/*'.format(dataset)\n",
    "else:\n",
    "    train_dataset_path = './data/{0}/train_small/*'.format(dataset)\n",
    "    validation_dataset_path = './data/{0}/val_small/*'.format(dataset)\n",
    "    test_dataset_path = './data/{0}/test_small/*'.format(dataset)\n",
    "\n",
    "print(train_dataset_path)\n",
    "print(validation_dataset_path)\n",
    "print(test_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpint_path_p = './saved_models/weights.best.train.mscoco.p.hdf5'\n",
    "checkpoint_path_p16 = './saved_models/weights.best.train.mscoco.p16.hdf5'\n",
    "checkpoint_path_p19 = './saved_models/weights.best.train.mscoco.p19.hdf5'\n",
    "checkpoint_path_t = './saved_models/weights.best.train.mscoco.t.hdf5'\n",
    "checkpoint_path_pt = './saved_models/weights.best.train.mscoco.pt.hdf5'\n",
    "checkpoint_path_pt16 = './saved_models/weights.best.train.mscoco.pt16.hdf5'\n",
    "checkpoint_path_pt16_bci = './saved_models/weights.best.train.mscoco.pt16_bci.hdf5'\n",
    "checkpoint_path_pt_bci = './saved_models/weights.best.train.mscoco.pt_bci.hdf5'\n",
    "checkpoint_path_pt16_no_res = './saved_models/weights.best.train.mscoco.pt16_no_res.hdf5'\n",
    "\n",
    "if use_dataset_celeba:\n",
    "    checkpint_path_p = './saved_models/weights.best.train.celeba.p.hdf5'\n",
    "    checkpoint_path_p16 = './saved_models/weights.best.train.celeba.p16.hdf5'\n",
    "    checkpoint_path_p19 = './saved_models/weights.best.train.celeba.p19.hdf5'\n",
    "    checkpoint_path_t = './saved_models/weights.best.train.celeba.t.hdf5'\n",
    "    checkpoint_path_pt = './saved_models/weights.best.train.celeba.pt.hdf5'\n",
    "    checkpoint_path_pt16 = './saved_models/weights.best.train.celeba.pt16.hdf5'\n",
    "    checkpoint_path_pt16_bci = './saved_models/weights.best.train.celeba.pt16_bci.hdf5'\n",
    "    checkpoint_path_pt_bci = './saved_models/weights.best.train.celeba.pt_bci.hdf5'\n",
    "    checkpoint_path_pt16_no_res = './saved_models/weights.best.train.celeba.pt16_no_res.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Some of the parameters are used from the global space\n",
    "def model_train(model, optimizer, loss_function, checkpoint_path, verbose=2):\n",
    "    if load_weights_before_training:\n",
    "        if check_path_exists(checkpoint_path):\n",
    "            model.load_weights(checkpoint_path)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint(filepath=checkpoint_path, \n",
    "                               verbose=verbose, save_best_only=True)\n",
    "    early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=verbose)\n",
    "\n",
    "    model.fit(train_data_tensors, train_truth_tensors,\n",
    "              validation_data=(validation_data_tensors, validation_truth_tensors),\n",
    "              epochs=train_epochs, batch_size=train_batch_size, callbacks=[checkpointer, early_stopper], verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Some of the parameters are used from the global space\n",
    "def model_predict(model, checkpoint_path):\n",
    "    return\n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "    print('Predicting...')\n",
    "    predictions = model.predict(test_data_tensors)\n",
    "\n",
    "    print('Plotting the results...')\n",
    "    plot_images_for_compare_separate(test_data_tensors, predictions, test_truth_tensors, test_image_index_to_show)\n",
    "\n",
    "    print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Some of the parameters are used from the global space\n",
    "def model_predict_2(model, checkpoint_path):\n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "    print('Predicting...')\n",
    "    predictions = model.predict(test_data_tensors)\n",
    "\n",
    "    print('Plotting the results...')\n",
    "    plot_images_for_compare(test_data_tensors, predictions, test_truth_tensors, test_image_index_to_show)\n",
    "\n",
    "    print('All done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create models, train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_p(get_model_only=False, summary=False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if not get_model_only:\n",
    "        model = generator_with_residual(input_shape=train_data.shape[1:], summary=False, add_bicubic=False)\n",
    "        if not disable_training:\n",
    "            model_train(model=model, optimizer=optimizer, loss_function=perceptual_loss, checkpoint_path=perceptual_loss_checkpint_path,\n",
    "                        verbose=training_verbose)\n",
    "        model_predict(model, perceptual_loss_checkpint_path)\n",
    "        # Free the memory\n",
    "        del model\n",
    "        gc.collect()\n",
    "    \n",
    "    # Recreate the model and return it\n",
    "    return generator_with_residual(input_shape=train_data.shape[1:], summary=False, add_bicubic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the functions to load the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training, we use all color images in MSCOCO [31]\n",
    "that have at least 384 pixels on the short side resulting in\n",
    "roughly 200k images. All images are cropped centrally to a\n",
    "square and then downsampled to 256×256 to reduce noise\n",
    "and JPEG artifacts. During training, we fix the size of the\n",
    "input ILR to 32×32. As the scale of objects in the MSCOCO\n",
    "dataset is too small when downsampled to such a small size,\n",
    "we downsample the 256×256 images by \u000b",
    " and then crop\n",
    "these to patches of size 32×32. After training the model\n",
    "for any given scaling factor \u000b",
    ", the input to the fully convolutional\n",
    "network at test time can be an image of arbitrary\n",
    "dimensions w×h which is then upscaled to (\u000b",
    "w)×(\u000b",
    "h)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:12<00:00, 45.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 48.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 79.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images:  600\n",
      "Validation images:  100\n",
      "Test images:  20\n"
     ]
    }
   ],
   "source": [
    "print('Loading train data:')\n",
    "train_data, train_truth = load_images_with_truth(train_dataset_path, 4)\n",
    "print('Loading validation data:')\n",
    "validation_data, validation_truth = load_images_with_truth(validation_dataset_path, 4)\n",
    "print('Loading test data:')\n",
    "test_data, test_truth = load_images_with_truth(test_dataset_path, 4)\n",
    "\n",
    "print(\"Train images: \", len(train_data))\n",
    "print('Validation images: ', len(validation_data))\n",
    "print(\"Test images: \", len(test_data))\n",
    "\n",
    "train_data_tensors = train_data.astype('float32')/255\n",
    "train_truth_tensors = train_truth.astype('float32')/255\n",
    "\n",
    "validation_data_tensors = validation_data.astype('float32')/255\n",
    "validation_truth_tensors = validation_truth.astype('float32')/255\n",
    "\n",
    "test_data_tensors = test_data.astype('float32')/255\n",
    "test_truth_tensors = test_truth.astype('float32')/255\n",
    "\n",
    "train_data_shape = (32, 32, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to create separate models even though that they are based on the same architecture. This is because we want to have new default parameters each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training P\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      " - 36s - loss: 0.2620 - acc: 0.5216 - val_loss: 0.1717 - val_acc: 0.6915\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17168, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n",
      "Epoch 2/10\n",
      " - 28s - loss: 0.1554 - acc: 0.6795 - val_loss: 0.1390 - val_acc: 0.7833\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.17168 to 0.13898, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n",
      "Epoch 3/10\n",
      " - 24s - loss: 0.1348 - acc: 0.7463 - val_loss: 0.1273 - val_acc: 0.7754\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13898 to 0.12731, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n",
      "Epoch 4/10\n",
      " - 24s - loss: 0.1278 - acc: 0.7457 - val_loss: 0.1246 - val_acc: 0.7998\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.12731 to 0.12459, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n",
      "Epoch 5/10\n",
      " - 24s - loss: 0.1233 - acc: 0.7570 - val_loss: 0.1207 - val_acc: 0.8078\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.12459 to 0.12074, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n",
      "Epoch 6/10\n",
      " - 24s - loss: 0.1195 - acc: 0.7743 - val_loss: 0.1185 - val_acc: 0.8197\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.12074 to 0.11854, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n",
      "Epoch 7/10\n",
      " - 24s - loss: 0.1167 - acc: 0.7620 - val_loss: 0.1180 - val_acc: 0.7524\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.11854 to 0.11798, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n",
      "Epoch 8/10\n",
      " - 24s - loss: 0.1146 - acc: 0.7574 - val_loss: 0.1169 - val_acc: 0.8163\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.11798 to 0.11694, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n",
      "Epoch 9/10\n",
      " - 24s - loss: 0.1125 - acc: 0.7590 - val_loss: 0.1159 - val_acc: 0.8218\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.11694 to 0.11589, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n",
      "Epoch 10/10\n",
      " - 24s - loss: 0.1095 - acc: 0.7809 - val_loss: 0.1132 - val_acc: 0.8255\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.11589 to 0.11324, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n"
     ]
    }
   ],
   "source": [
    "if enable_p:\n",
    "    model_p = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    if not disable_training:\n",
    "        print(\"Training P\")\n",
    "        model_train(model=model_p, optimizer=optimizer, loss_function=perceptual_loss,\n",
    "                    checkpoint_path=checkpint_path_p, verbose=training_verbose)\n",
    "    model_predict(model_p, checkpint_path_p)\n",
    "    del model_p\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peceptual loss based on VGG19 (block3_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training P19\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      " - 17s - loss: 231.1760 - acc: 0.5717 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 239.63498, saving model to ./saved_models/weights.best.train.mscoco.p19.hdf5\n",
      "Epoch 2/10\n",
      " - 16s - loss: 230.2551 - acc: 0.5856 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 239.63498\n",
      "Epoch 3/10\n",
      " - 16s - loss: 230.2551 - acc: 0.5856 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 239.63498\n",
      "Epoch 4/10\n",
      " - 16s - loss: 230.2551 - acc: 0.5856 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 239.63498\n",
      "Epoch 5/10\n",
      " - 16s - loss: 230.2551 - acc: 0.5856 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 239.63498\n",
      "Epoch 6/10\n",
      " - 16s - loss: 230.2551 - acc: 0.5856 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 239.63498\n",
      "Epoch 7/10\n",
      " - 16s - loss: 230.2551 - acc: 0.5856 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 239.63498\n",
      "Epoch 8/10\n",
      " - 16s - loss: 230.2551 - acc: 0.5856 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 239.63498\n",
      "Epoch 9/10\n",
      " - 16s - loss: 230.2551 - acc: 0.5856 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 239.63498\n",
      "Epoch 10/10\n",
      " - 16s - loss: 230.2551 - acc: 0.5856 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 239.63498\n"
     ]
    }
   ],
   "source": [
    "if enable_p19:\n",
    "    model_p19 = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    if not disable_training:\n",
    "        print(\"Training P19\")\n",
    "        model_train(model=model_p19, optimizer=optimizer, loss_function=perceptual_loss_19,\n",
    "                    checkpoint_path=checkpoint_path_p19)\n",
    "    model_predict(model=model_p19, checkpoint_path=checkpoint_path_p19)\n",
    "    del model_p19\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peceptual loss based on VGG16 (block3_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training P16\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      " - 16s - loss: 444.4024 - acc: 0.5522 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 110.13608, saving model to ./saved_models/weights.best.train.mscoco.p16.hdf5\n",
      "Epoch 2/10\n",
      " - 15s - loss: 106.0178 - acc: 0.5856 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 110.13608\n",
      "Epoch 3/10\n",
      " - 15s - loss: 106.0178 - acc: 0.5856 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 110.13608\n",
      "Epoch 4/10\n",
      " - 15s - loss: 106.0178 - acc: 0.5856 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 110.13608\n",
      "Epoch 5/10\n",
      " - 15s - loss: 106.0178 - acc: 0.5856 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 110.13608\n",
      "Epoch 6/10\n",
      " - 15s - loss: 106.0178 - acc: 0.5856 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 110.13608\n",
      "Epoch 7/10\n",
      " - 15s - loss: 106.0178 - acc: 0.5856 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 110.13608\n",
      "Epoch 8/10\n",
      " - 15s - loss: 106.0178 - acc: 0.5856 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 110.13608\n",
      "Epoch 9/10\n",
      " - 15s - loss: 106.0178 - acc: 0.5856 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 110.13608\n",
      "Epoch 10/10\n",
      " - 15s - loss: 106.0178 - acc: 0.5856 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 110.13608\n"
     ]
    }
   ],
   "source": [
    "if enable_p16:\n",
    "    model_p16 = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    if not disable_training:\n",
    "        print(\"Training P16\")\n",
    "        model_train(model=model_p16, optimizer=optimizer, loss_function=perceptual_loss_16,\n",
    "                    checkpoint_path=checkpoint_path_p16, verbose=training_verbose)\n",
    "    model_predict(model=model_p16, checkpoint_path=checkpoint_path_p16)\n",
    "    del model_p16\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texture loss (multi layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training T\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      " - 22s - loss: 1.4429 - acc: 0.2665 - val_loss: 1.0660 - val_acc: 0.2684\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.06599, saving model to ./saved_models/weights.best.train.mscoco.t.hdf5\n",
      "Epoch 2/10\n",
      " - 20s - loss: 0.9625 - acc: 0.2547 - val_loss: 0.8965 - val_acc: 0.2684\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.06599 to 0.89652, saving model to ./saved_models/weights.best.train.mscoco.t.hdf5\n",
      "Epoch 3/10\n",
      " - 20s - loss: 0.8992 - acc: 0.2549 - val_loss: 0.8789 - val_acc: 0.2708\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.89652 to 0.87889, saving model to ./saved_models/weights.best.train.mscoco.t.hdf5\n",
      "Epoch 4/10\n",
      " - 20s - loss: 0.8581 - acc: 0.2583 - val_loss: 0.8183 - val_acc: 0.2733\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.87889 to 0.81834, saving model to ./saved_models/weights.best.train.mscoco.t.hdf5\n",
      "Epoch 5/10\n",
      " - 20s - loss: 0.7888 - acc: 0.2617 - val_loss: 0.7627 - val_acc: 0.2750\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.81834 to 0.76269, saving model to ./saved_models/weights.best.train.mscoco.t.hdf5\n",
      "Epoch 6/10\n",
      " - 20s - loss: 0.7577 - acc: 0.2644 - val_loss: 0.7308 - val_acc: 0.2772\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.76269 to 0.73085, saving model to ./saved_models/weights.best.train.mscoco.t.hdf5\n",
      "Epoch 7/10\n",
      " - 20s - loss: 0.7458 - acc: 0.2656 - val_loss: 0.6938 - val_acc: 0.2806\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.73085 to 0.69381, saving model to ./saved_models/weights.best.train.mscoco.t.hdf5\n",
      "Epoch 8/10\n",
      " - 20s - loss: 0.8714 - acc: 0.2619 - val_loss: 0.8919 - val_acc: 0.2684\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.69381\n",
      "Epoch 9/10\n",
      " - 20s - loss: 0.8946 - acc: 0.2547 - val_loss: 0.8792 - val_acc: 0.2684\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.69381\n",
      "Epoch 10/10\n",
      " - 20s - loss: 0.8793 - acc: 0.2547 - val_loss: 0.8569 - val_acc: 0.2684\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.69381\n"
     ]
    }
   ],
   "source": [
    "if enable_t:\n",
    "    model_t = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    if not disable_training:\n",
    "        print(\"Training T\")\n",
    "        model_train(model=model_t, optimizer=optimizer, loss_function=texture_loss_multi_layers,\n",
    "                    checkpoint_path=checkpoint_path_t, verbose=training_verbose)\n",
    "    model_predict(model=model_t, checkpoint_path=checkpoint_path_t)\n",
    "    del model_t\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texture loss plus perceptual loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PT\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      " - 40s - loss: 2.6850 - acc: 0.5439 - val_loss: 2.4461 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.44613, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n",
      "Epoch 2/10\n",
      " - 37s - loss: 2.2762 - acc: 0.5851 - val_loss: 2.0503 - val_acc: 0.5407\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.44613 to 2.05033, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n",
      "Epoch 3/10\n",
      " - 38s - loss: 1.8646 - acc: 0.5570 - val_loss: 1.6502 - val_acc: 0.5366\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.05033 to 1.65016, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n",
      "Epoch 4/10\n",
      " - 38s - loss: 1.5780 - acc: 0.5725 - val_loss: 1.4841 - val_acc: 0.5379\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.65016 to 1.48409, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n",
      "Epoch 5/10\n",
      " - 38s - loss: 1.4603 - acc: 0.5735 - val_loss: 1.4138 - val_acc: 0.5245\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.48409 to 1.41379, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n",
      "Epoch 6/10\n",
      " - 38s - loss: 1.4021 - acc: 0.5765 - val_loss: 1.3663 - val_acc: 0.5355\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.41379 to 1.36629, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n",
      "Epoch 7/10\n",
      " - 38s - loss: 1.3598 - acc: 0.5745 - val_loss: 1.3379 - val_acc: 0.5312\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.36629 to 1.33791, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n",
      "Epoch 8/10\n",
      " - 38s - loss: 1.3403 - acc: 0.5716 - val_loss: 1.3250 - val_acc: 0.5336\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.33791 to 1.32503, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n",
      "Epoch 9/10\n",
      " - 38s - loss: 1.3176 - acc: 0.5665 - val_loss: 1.2994 - val_acc: 0.5346\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.32503 to 1.29937, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n",
      "Epoch 10/10\n",
      " - 38s - loss: 1.3033 - acc: 0.5640 - val_loss: 1.2926 - val_acc: 0.5221\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.29937 to 1.29257, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n"
     ]
    }
   ],
   "source": [
    "if enable_pt:\n",
    "    model_pt = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    if not disable_training:\n",
    "        print(\"Training PT\")\n",
    "        model_train(model=model_pt, optimizer=optimizer, loss_function=perceptual_plus_texture_loss,\n",
    "                    checkpoint_path=checkpoint_path_pt, verbose=training_verbose)\n",
    "    model_predict(model=model_pt, checkpoint_path=checkpoint_path_pt)\n",
    "    del model_pt\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peceptual loss 16 + texture loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training P16\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      " - 29s - loss: 849488.8927 - acc: 0.5785 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 110.39398, saving model to ./saved_models/weights.best.train.mscoco.pt16.hdf5\n",
      "Epoch 2/10\n",
      " - 27s - loss: 106.2785 - acc: 0.5856 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 110.39398\n",
      "Epoch 3/10\n",
      " - 27s - loss: 106.2785 - acc: 0.5856 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 110.39398\n",
      "Epoch 4/10\n",
      " - 27s - loss: 106.2785 - acc: 0.5856 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 110.39398\n",
      "Epoch 5/10\n",
      " - 27s - loss: 106.2785 - acc: 0.5856 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 110.39398\n",
      "Epoch 6/10\n",
      " - 27s - loss: 106.2785 - acc: 0.5856 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 110.39398\n",
      "Epoch 7/10\n",
      " - 27s - loss: 106.2785 - acc: 0.5856 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 110.39398\n",
      "Epoch 8/10\n",
      " - 27s - loss: 106.2785 - acc: 0.5856 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 110.39398\n",
      "Epoch 9/10\n",
      " - 27s - loss: 106.2785 - acc: 0.5856 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 110.39398\n",
      "Epoch 10/10\n",
      " - 27s - loss: 106.2785 - acc: 0.5856 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 110.39398\n"
     ]
    }
   ],
   "source": [
    "if enable_pt16:\n",
    "    model_pt16 = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    if not disable_training:\n",
    "        print(\"Training P16\")\n",
    "        model_train(model=model_pt16, optimizer=optimizer, loss_function=perceptual_16_plus_texture_loss,\n",
    "                    checkpoint_path=checkpoint_path_pt16, verbose=training_verbose)\n",
    "    model_predict(model=model_pt16, checkpoint_path=checkpoint_path_pt16)\n",
    "    del model_pt16\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try some with bicubic interpolation included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peceptual loss 16 + texture loss. Bicubic interpolation included in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PT16_BCI\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[8,32,32,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node loss_6/add_71_loss/truediv_5-0-0-TransposeNCHWToNHWC-LayoutOptimizer}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](loss_6/add_71_loss/truediv_5, loss_6/add_71_loss/Mean-1-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss_6/mul/_7501}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3581_loss_6/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-f874424509af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training PT16_BCI\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         model_train(model=model_pt16_bci, optimizer=optimizer, loss_function=perceptual_16_plus_texture_loss,\n\u001b[1;32m----> 6\u001b[1;33m                     checkpoint_path=checkpoint_path_pt16_bci, verbose=training_verbose)\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mmodel_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_pt16_bci\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint_path_pt16_bci\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mmodel_pt16_bci\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-c16202c4ba8c>\u001b[0m in \u001b[0;36mmodel_train\u001b[1;34m(model, optimizer, loss_function, checkpoint_path, verbose)\u001b[0m\n\u001b[0;32m     12\u001b[0m     model.fit(train_data_tensors, train_truth_tensors,\n\u001b[0;32m     13\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_data_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_truth_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m               epochs=train_epochs, batch_size=train_batch_size, callbacks=[checkpointer, early_stopper], verbose=verbose)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[8,32,32,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node loss_6/add_71_loss/truediv_5-0-0-TransposeNCHWToNHWC-LayoutOptimizer}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](loss_6/add_71_loss/truediv_5, loss_6/add_71_loss/Mean-1-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss_6/mul/_7501}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3581_loss_6/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "if enable_pt16_bci:\n",
    "    model_pt16_bci = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=True)\n",
    "    if not disable_training:\n",
    "        print(\"Training PT16_BCI\")\n",
    "        model_train(model=model_pt16_bci, optimizer=optimizer, loss_function=perceptual_16_plus_texture_loss,\n",
    "                    checkpoint_path=checkpoint_path_pt16_bci, verbose=training_verbose)\n",
    "    model_predict(model=model_pt16_bci, checkpoint_path=checkpoint_path_pt16_bci)\n",
    "    del model_pt16_bci\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptual plus texture loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_pt_bci:\n",
    "    model_pt_bci = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=True)\n",
    "    if not disable_training:\n",
    "        print(\"Training PT_BCI\")\n",
    "        model_train(model=model_pt_bci, optimizer=optimizer, loss_function=perceptual_plus_texture_loss,\n",
    "                    checkpoint_path=checkpoint_path_pt_bci, verbose=training_verbose)\n",
    "    model_predict(model=model_pt_bci, checkpoint_path=checkpoint_path_pt_bci)\n",
    "    del model_pt_bci\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peceptual loss 16 + texture loss. No residual network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_pt16_no_res:\n",
    "    model_pt16_no_res = generator_no_residual(input_shape=train_data_shape, summary=False)\n",
    "    if not disable_training:\n",
    "        print(\"Training PT16_NO_RES\")\n",
    "        model_train(model=model_pt16_no_res, optimizer=optimizer,\n",
    "                    loss_function=perceptual_16_plus_texture_loss,\n",
    "                    checkpoint_path=checkpoint_path_pt16_no_res, verbose=training_verbose)\n",
    "    model_predict(model=model_pt16_no_res,\n",
    "                  checkpoint_path=checkpoint_path_pt16_no_res)\n",
    "    del model_pt16_no_res\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare all of the models at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_data = []\n",
    "\n",
    "if enable_p:\n",
    "    model_p = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    models_data.append({'name': \"P\", 'model': model_p, 'checkpoint': checkpint_path_p})\n",
    "\n",
    "if enable_p19:\n",
    "    model_p19 = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    models_data.append({'name': \"P VGG19\", 'model': model_p19, 'checkpoint': checkpoint_path_p19})\n",
    "\n",
    "if enable_p16:\n",
    "    model_p16 = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    models_data.append({'name': \"P VGG16\", 'model': model_p16, 'checkpoint': checkpoint_path_p16})\n",
    "\n",
    "if enable_t:\n",
    "    model_t = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    models_data.append({'name': \"T\", 'model': model_t, 'checkpoint': checkpoint_path_t})\n",
    "\n",
    "if enable_pt:\n",
    "    model_pt = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    models_data.append({'name': \"PT\", 'model': model_pt,\n",
    "                        'checkpoint': checkpoint_path_pt})\n",
    "\n",
    "if enable_pt16:\n",
    "    model_pt16 = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    models_data.append({'name': \"PT VGG16\", 'model': model_pt16,\n",
    "                        'checkpoint': checkpoint_path_pt16})\n",
    "\n",
    "if enable_pt16_bci:\n",
    "    model_pt16_bci = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=True)\n",
    "    models_data.append({'name': \"PT VGG16 (BCI)\", 'model': model_pt16_bci,\n",
    "                        'checkpoint': checkpoint_path_pt16_bci})\n",
    "\n",
    "if enable_pt_bci:\n",
    "    model_pt_bci = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=True)\n",
    "    models_data.append({'name': \"PT (BCI)\", 'model': model_pt_bci,\n",
    "                        'checkpoint': checkpoint_path_pt_bci})\n",
    "\n",
    "if enable_pt16_no_res:\n",
    "    model_pt16_no_res = generator_no_residual(input_shape=train_data_shape, summary=False)\n",
    "    models_data.append({'name': \"PT VGG16 (NR)\", 'model': model_pt16_no_res,\n",
    "                        'checkpoint': checkpoint_path_pt16_no_res})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the images in higher dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models_single_image(test_data_tensors, test_truth_tensors, models_data, test_image_index_to_show, show_input=True, show_interpolated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
