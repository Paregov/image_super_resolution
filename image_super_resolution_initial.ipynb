{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing an image super resolution.\n",
    "## Here I'm going to do some quick training as proof of concept (PoC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from models import generator_no_residual, generator_with_residual, discriminator\n",
    "from utils import check_path_exists\n",
    "from data_loader import load_images_with_truth\n",
    "from loss_functions import perceptual_loss, perceptual_loss_16, perceptual_loss_19\n",
    "from loss_functions import texture_loss_multi_layers, perceptual_plus_texture_loss, perceptual_16_plus_texture_loss\n",
    "from visualizations import plot_images_for_compare, plot_images_for_compare_separate, compare_models, compare_models_single_image\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable this flag if running on the laptop with smaller GPU.\n",
    "running_on_laptop = True\n",
    "\n",
    "# This will use the smaller datasets (train_small, val_small, test_small).\n",
    "use_small_dataset = True\n",
    "\n",
    "# Set to true if you want to use CelebA dataset. Otherwise it will use MS COCO.\n",
    "use_dataset_celeba = False\n",
    "\n",
    "# Set to true and it will not execute training. Usefull when just want to plot the results.\n",
    "disable_training = False\n",
    "\n",
    "# Set to true if you want to load the current weights from the folder before training, so you can\n",
    "# continue with the training\n",
    "load_weights_before_training = False\n",
    "\n",
    "# What to be the verbose level during training.\n",
    "training_verbose = 2\n",
    "\n",
    "enable_p = True\n",
    "enable_p16 = True\n",
    "enable_p19 = True\n",
    "enable_t = True\n",
    "enable_pt = True\n",
    "enable_pt16 = True\n",
    "enable_pt16_bci = True\n",
    "enable_pt_bci = True\n",
    "enable_pt16_no_res = True\n",
    "\n",
    "train_epochs = 100\n",
    "train_batch_size = 32\n",
    "test_image_index_to_show = range(20)\n",
    "optimizer = Adam(lr=0.0001)\n",
    "\n",
    "if running_on_laptop:\n",
    "    train_epochs = 10\n",
    "    train_batch_size = 8\n",
    "    test_image_index_to_show = range(20)\n",
    "    optimizer = Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/MSCOCO/train_small/*\n",
      "./data/MSCOCO/val_small/*\n",
      "./data/MSCOCO/test_small/*\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset path\n",
    "dataset = \"MSCOCO\"\n",
    "if use_dataset_celeba:\n",
    "    dataset = \"celeba\"\n",
    "\n",
    "if not use_small_dataset:\n",
    "    train_dataset_path = './data/{0}/train/*'.format(dataset)\n",
    "    validation_dataset_path = './data/{0}/val/*'.format(dataset)\n",
    "    test_dataset_path = './data/{0}/test/*'.format(dataset)\n",
    "else:\n",
    "    train_dataset_path = './data/{0}/train_small/*'.format(dataset)\n",
    "    validation_dataset_path = './data/{0}/val_small/*'.format(dataset)\n",
    "    test_dataset_path = './data/{0}/test_small/*'.format(dataset)\n",
    "\n",
    "print(train_dataset_path)\n",
    "print(validation_dataset_path)\n",
    "print(test_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpint_path_p = './saved_models/weights.best.train.mscoco.p.hdf5'\n",
    "checkpoint_path_p16 = './saved_models/weights.best.train.mscoco.p16.hdf5'\n",
    "checkpoint_path_p19 = './saved_models/weights.best.train.mscoco.p19.hdf5'\n",
    "checkpoint_path_t = './saved_models/weights.best.train.mscoco.t.hdf5'\n",
    "checkpoint_path_pt = './saved_models/weights.best.train.mscoco.pt.hdf5'\n",
    "checkpoint_path_pt16 = './saved_models/weights.best.train.mscoco.pt16.hdf5'\n",
    "checkpoint_path_pt16_bci = './saved_models/weights.best.train.mscoco.pt16_bci.hdf5'\n",
    "checkpoint_path_pt_bci = './saved_models/weights.best.train.mscoco.pt_bci.hdf5'\n",
    "checkpoint_path_pt16_no_res = './saved_models/weights.best.train.mscoco.pt16_no_res.hdf5'\n",
    "\n",
    "if use_dataset_celeba:\n",
    "    checkpint_path_p = './saved_models/weights.best.train.celeba.p.hdf5'\n",
    "    checkpoint_path_p16 = './saved_models/weights.best.train.celeba.p16.hdf5'\n",
    "    checkpoint_path_p19 = './saved_models/weights.best.train.celeba.p19.hdf5'\n",
    "    checkpoint_path_t = './saved_models/weights.best.train.celeba.t.hdf5'\n",
    "    checkpoint_path_pt = './saved_models/weights.best.train.celeba.pt.hdf5'\n",
    "    checkpoint_path_pt16 = './saved_models/weights.best.train.celeba.pt16.hdf5'\n",
    "    checkpoint_path_pt16_bci = './saved_models/weights.best.train.celeba.pt16_bci.hdf5'\n",
    "    checkpoint_path_pt_bci = './saved_models/weights.best.train.celeba.pt_bci.hdf5'\n",
    "    checkpoint_path_pt16_no_res = './saved_models/weights.best.train.celeba.pt16_no_res.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Some of the parameters are used from the global space\n",
    "def model_train(model, optimizer, loss_function, checkpoint_path, verbose=2):\n",
    "    if load_weights_before_training:\n",
    "        if check_path_exists(checkpoint_path):\n",
    "            model.load_weights(checkpoint_path)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint(filepath=checkpoint_path, \n",
    "                               verbose=verbose, save_best_only=True)\n",
    "    early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=verbose)\n",
    "\n",
    "    model.fit(train_data_tensors, train_truth_tensors,\n",
    "              validation_data=(validation_data_tensors, validation_truth_tensors),\n",
    "              epochs=train_epochs, batch_size=train_batch_size, callbacks=[checkpointer, early_stopper], verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Some of the parameters are used from the global space\n",
    "def model_predict(model, checkpoint_path):\n",
    "    return\n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "    print('Predicting...')\n",
    "    predictions = model.predict(test_data_tensors)\n",
    "\n",
    "    print('Plotting the results...')\n",
    "    plot_images_for_compare_separate(test_data_tensors, predictions, test_truth_tensors, test_image_index_to_show)\n",
    "\n",
    "    print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Some of the parameters are used from the global space\n",
    "def model_predict_2(model, checkpoint_path):\n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "    print('Predicting...')\n",
    "    predictions = model.predict(test_data_tensors)\n",
    "\n",
    "    print('Plotting the results...')\n",
    "    plot_images_for_compare(test_data_tensors, predictions, test_truth_tensors, test_image_index_to_show)\n",
    "\n",
    "    print('All done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create models, train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_p(get_model_only=False, summary=False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if not get_model_only:\n",
    "        model = generator_with_residual(input_shape=train_data.shape[1:], summary=False, add_bicubic=False)\n",
    "        if not disable_training:\n",
    "            model_train(model=model, optimizer=optimizer, loss_function=perceptual_loss, checkpoint_path=perceptual_loss_checkpint_path,\n",
    "                        verbose=training_verbose)\n",
    "        model_predict(model, perceptual_loss_checkpint_path)\n",
    "        # Free the memory\n",
    "        del model\n",
    "        gc.collect()\n",
    "    \n",
    "    # Recreate the model and return it\n",
    "    return generator_with_residual(input_shape=train_data.shape[1:], summary=False, add_bicubic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the functions to load the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training, we use all color images in MSCOCO [31]\n",
    "that have at least 384 pixels on the short side resulting in\n",
    "roughly 200k images. All images are cropped centrally to a\n",
    "square and then downsampled to 256Ã—256 to reduce noise\n",
    "and JPEG artifacts. During training, we fix the size of the\n",
    "input ILR to 32Ã—32. As the scale of objects in the MSCOCO\n",
    "dataset is too small when downsampled to such a small size,\n",
    "we downsample the 256Ã—256 images by \u000b",
    " and then crop\n",
    "these to patches of size 32Ã—32. After training the model\n",
    "for any given scaling factor \u000b",
    ", the input to the fully convolutional\n",
    "network at test time can be an image of arbitrary\n",
    "dimensions wÃ—h which is then upscaled to (\u000b",
    "w)Ã—(\u000b",
    "h)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:12<00:00, 45.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:02<00:00, 48.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 79.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images:  600\n",
      "Validation images:  100\n",
      "Test images:  20\n"
     ]
    }
   ],
   "source": [
    "print('Loading train data:')\n",
    "train_data, train_truth = load_images_with_truth(train_dataset_path, 4)\n",
    "print('Loading validation data:')\n",
    "validation_data, validation_truth = load_images_with_truth(validation_dataset_path, 4)\n",
    "print('Loading test data:')\n",
    "test_data, test_truth = load_images_with_truth(test_dataset_path, 4)\n",
    "\n",
    "print(\"Train images: \", len(train_data))\n",
    "print('Validation images: ', len(validation_data))\n",
    "print(\"Test images: \", len(test_data))\n",
    "\n",
    "train_data_tensors = train_data.astype('float32')/255\n",
    "train_truth_tensors = train_truth.astype('float32')/255\n",
    "\n",
    "validation_data_tensors = validation_data.astype('float32')/255\n",
    "validation_truth_tensors = validation_truth.astype('float32')/255\n",
    "\n",
    "test_data_tensors = test_data.astype('float32')/255\n",
    "test_truth_tensors = test_truth.astype('float32')/255\n",
    "\n",
    "train_data_shape = (32, 32, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to create separate models even though that they are based on the same architecture. This is because we want to have new default parameters each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training P\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      " - 36s - loss: 0.2620 - acc: 0.5216 - val_loss: 0.1717 - val_acc: 0.6915\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17168, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n",
      "Epoch 2/10\n",
      " - 28s - loss: 0.1554 - acc: 0.6795 - val_loss: 0.1390 - val_acc: 0.7833\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.17168 to 0.13898, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n",
      "Epoch 3/10\n",
      " - 24s - loss: 0.1348 - acc: 0.7463 - val_loss: 0.1273 - val_acc: 0.7754\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13898 to 0.12731, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n",
      "Epoch 4/10\n",
      " - 24s - loss: 0.1278 - acc: 0.7457 - val_loss: 0.1246 - val_acc: 0.7998\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.12731 to 0.12459, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n",
      "Epoch 5/10\n",
      " - 24s - loss: 0.1233 - acc: 0.7570 - val_loss: 0.1207 - val_acc: 0.8078\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.12459 to 0.12074, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n",
      "Epoch 6/10\n",
      " - 24s - loss: 0.1195 - acc: 0.7743 - val_loss: 0.1185 - val_acc: 0.8197\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.12074 to 0.11854, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n",
      "Epoch 7/10\n",
      " - 24s - loss: 0.1167 - acc: 0.7620 - val_loss: 0.1180 - val_acc: 0.7524\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.11854 to 0.11798, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n",
      "Epoch 8/10\n",
      " - 24s - loss: 0.1146 - acc: 0.7574 - val_loss: 0.1169 - val_acc: 0.8163\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.11798 to 0.11694, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n",
      "Epoch 9/10\n",
      " - 24s - loss: 0.1125 - acc: 0.7590 - val_loss: 0.1159 - val_acc: 0.8218\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.11694 to 0.11589, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n",
      "Epoch 10/10\n",
      " - 24s - loss: 0.1095 - acc: 0.7809 - val_loss: 0.1132 - val_acc: 0.8255\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.11589 to 0.11324, saving model to ./saved_models/weights.best.train.mscoco.p.hdf5\n"
     ]
    }
   ],
   "source": [
    "if enable_p:\n",
    "    model_p = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    if not disable_training:\n",
    "        print(\"Training P\")\n",
    "        model_train(model=model_p, optimizer=optimizer, loss_function=perceptual_loss,\n",
    "                    checkpoint_path=checkpint_path_p, verbose=training_verbose)\n",
    "    model_predict(model_p, checkpint_path_p)\n",
    "    del model_p\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peceptual loss based on VGG19 (block3_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training P19\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      " - 17s - loss: 231.1760 - acc: 0.5717 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 239.63498, saving model to ./saved_models/weights.best.train.mscoco.p19.hdf5\n",
      "Epoch 2/10\n",
      " - 16s - loss: 230.2551 - acc: 0.5856 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 239.63498\n",
      "Epoch 3/10\n",
      " - 16s - loss: 230.2551 - acc: 0.5856 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 239.63498\n",
      "Epoch 4/10\n",
      " - 16s - loss: 230.2551 - acc: 0.5856 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 239.63498\n",
      "Epoch 5/10\n",
      " - 16s - loss: 230.2551 - acc: 0.5856 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 239.63498\n",
      "Epoch 6/10\n",
      " - 16s - loss: 230.2551 - acc: 0.5856 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 239.63498\n",
      "Epoch 7/10\n",
      " - 16s - loss: 230.2551 - acc: 0.5856 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 239.63498\n",
      "Epoch 8/10\n",
      " - 16s - loss: 230.2551 - acc: 0.5856 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 239.63498\n",
      "Epoch 9/10\n",
      " - 16s - loss: 230.2551 - acc: 0.5856 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 239.63498\n",
      "Epoch 10/10\n",
      " - 16s - loss: 230.2551 - acc: 0.5856 - val_loss: 239.6350 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 239.63498\n"
     ]
    }
   ],
   "source": [
    "if enable_p19:\n",
    "    model_p19 = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    if not disable_training:\n",
    "        print(\"Training P19\")\n",
    "        model_train(model=model_p19, optimizer=optimizer, loss_function=perceptual_loss_19,\n",
    "                    checkpoint_path=checkpoint_path_p19)\n",
    "    model_predict(model=model_p19, checkpoint_path=checkpoint_path_p19)\n",
    "    del model_p19\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peceptual loss based on VGG16 (block3_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training P16\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      " - 16s - loss: 444.4024 - acc: 0.5522 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 110.13608, saving model to ./saved_models/weights.best.train.mscoco.p16.hdf5\n",
      "Epoch 2/10\n",
      " - 15s - loss: 106.0178 - acc: 0.5856 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 110.13608\n",
      "Epoch 3/10\n",
      " - 15s - loss: 106.0178 - acc: 0.5856 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 110.13608\n",
      "Epoch 4/10\n",
      " - 15s - loss: 106.0178 - acc: 0.5856 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 110.13608\n",
      "Epoch 5/10\n",
      " - 15s - loss: 106.0178 - acc: 0.5856 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 110.13608\n",
      "Epoch 6/10\n",
      " - 15s - loss: 106.0178 - acc: 0.5856 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 110.13608\n",
      "Epoch 7/10\n",
      " - 15s - loss: 106.0178 - acc: 0.5856 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 110.13608\n",
      "Epoch 8/10\n",
      " - 15s - loss: 106.0178 - acc: 0.5856 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 110.13608\n",
      "Epoch 9/10\n",
      " - 15s - loss: 106.0178 - acc: 0.5856 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 110.13608\n",
      "Epoch 10/10\n",
      " - 15s - loss: 106.0178 - acc: 0.5856 - val_loss: 110.1361 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 110.13608\n"
     ]
    }
   ],
   "source": [
    "if enable_p16:\n",
    "    model_p16 = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    if not disable_training:\n",
    "        print(\"Training P16\")\n",
    "        model_train(model=model_p16, optimizer=optimizer, loss_function=perceptual_loss_16,\n",
    "                    checkpoint_path=checkpoint_path_p16, verbose=training_verbose)\n",
    "    model_predict(model=model_p16, checkpoint_path=checkpoint_path_p16)\n",
    "    del model_p16\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texture loss (multi layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training T\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      " - 22s - loss: 1.4429 - acc: 0.2665 - val_loss: 1.0660 - val_acc: 0.2684\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.06599, saving model to ./saved_models/weights.best.train.mscoco.t.hdf5\n",
      "Epoch 2/10\n",
      " - 20s - loss: 0.9625 - acc: 0.2547 - val_loss: 0.8965 - val_acc: 0.2684\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.06599 to 0.89652, saving model to ./saved_models/weights.best.train.mscoco.t.hdf5\n",
      "Epoch 3/10\n",
      " - 20s - loss: 0.8992 - acc: 0.2549 - val_loss: 0.8789 - val_acc: 0.2708\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.89652 to 0.87889, saving model to ./saved_models/weights.best.train.mscoco.t.hdf5\n",
      "Epoch 4/10\n",
      " - 20s - loss: 0.8581 - acc: 0.2583 - val_loss: 0.8183 - val_acc: 0.2733\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.87889 to 0.81834, saving model to ./saved_models/weights.best.train.mscoco.t.hdf5\n",
      "Epoch 5/10\n",
      " - 20s - loss: 0.7888 - acc: 0.2617 - val_loss: 0.7627 - val_acc: 0.2750\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.81834 to 0.76269, saving model to ./saved_models/weights.best.train.mscoco.t.hdf5\n",
      "Epoch 6/10\n",
      " - 20s - loss: 0.7577 - acc: 0.2644 - val_loss: 0.7308 - val_acc: 0.2772\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.76269 to 0.73085, saving model to ./saved_models/weights.best.train.mscoco.t.hdf5\n",
      "Epoch 7/10\n",
      " - 20s - loss: 0.7458 - acc: 0.2656 - val_loss: 0.6938 - val_acc: 0.2806\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.73085 to 0.69381, saving model to ./saved_models/weights.best.train.mscoco.t.hdf5\n",
      "Epoch 8/10\n",
      " - 20s - loss: 0.8714 - acc: 0.2619 - val_loss: 0.8919 - val_acc: 0.2684\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.69381\n",
      "Epoch 9/10\n",
      " - 20s - loss: 0.8946 - acc: 0.2547 - val_loss: 0.8792 - val_acc: 0.2684\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.69381\n",
      "Epoch 10/10\n",
      " - 20s - loss: 0.8793 - acc: 0.2547 - val_loss: 0.8569 - val_acc: 0.2684\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.69381\n"
     ]
    }
   ],
   "source": [
    "if enable_t:\n",
    "    model_t = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    if not disable_training:\n",
    "        print(\"Training T\")\n",
    "        model_train(model=model_t, optimizer=optimizer, loss_function=texture_loss_multi_layers,\n",
    "                    checkpoint_path=checkpoint_path_t, verbose=training_verbose)\n",
    "    model_predict(model=model_t, checkpoint_path=checkpoint_path_t)\n",
    "    del model_t\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texture loss plus perceptual loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PT\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      " - 40s - loss: 2.6850 - acc: 0.5439 - val_loss: 2.4461 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.44613, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n",
      "Epoch 2/10\n",
      " - 37s - loss: 2.2762 - acc: 0.5851 - val_loss: 2.0503 - val_acc: 0.5407\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.44613 to 2.05033, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n",
      "Epoch 3/10\n",
      " - 38s - loss: 1.8646 - acc: 0.5570 - val_loss: 1.6502 - val_acc: 0.5366\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.05033 to 1.65016, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n",
      "Epoch 4/10\n",
      " - 38s - loss: 1.5780 - acc: 0.5725 - val_loss: 1.4841 - val_acc: 0.5379\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.65016 to 1.48409, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n",
      "Epoch 5/10\n",
      " - 38s - loss: 1.4603 - acc: 0.5735 - val_loss: 1.4138 - val_acc: 0.5245\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.48409 to 1.41379, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n",
      "Epoch 6/10\n",
      " - 38s - loss: 1.4021 - acc: 0.5765 - val_loss: 1.3663 - val_acc: 0.5355\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.41379 to 1.36629, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n",
      "Epoch 7/10\n",
      " - 38s - loss: 1.3598 - acc: 0.5745 - val_loss: 1.3379 - val_acc: 0.5312\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.36629 to 1.33791, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n",
      "Epoch 8/10\n",
      " - 38s - loss: 1.3403 - acc: 0.5716 - val_loss: 1.3250 - val_acc: 0.5336\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.33791 to 1.32503, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n",
      "Epoch 9/10\n",
      " - 38s - loss: 1.3176 - acc: 0.5665 - val_loss: 1.2994 - val_acc: 0.5346\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.32503 to 1.29937, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n",
      "Epoch 10/10\n",
      " - 38s - loss: 1.3033 - acc: 0.5640 - val_loss: 1.2926 - val_acc: 0.5221\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.29937 to 1.29257, saving model to ./saved_models/weights.best.train.mscoco.pt.hdf5\n"
     ]
    }
   ],
   "source": [
    "if enable_pt:\n",
    "    model_pt = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    if not disable_training:\n",
    "        print(\"Training PT\")\n",
    "        model_train(model=model_pt, optimizer=optimizer, loss_function=perceptual_plus_texture_loss,\n",
    "                    checkpoint_path=checkpoint_path_pt, verbose=training_verbose)\n",
    "    model_predict(model=model_pt, checkpoint_path=checkpoint_path_pt)\n",
    "    del model_pt\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peceptual loss 16 + texture loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training P16\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      " - 29s - loss: 849488.8927 - acc: 0.5785 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 110.39398, saving model to ./saved_models/weights.best.train.mscoco.pt16.hdf5\n",
      "Epoch 2/10\n",
      " - 27s - loss: 106.2785 - acc: 0.5856 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 110.39398\n",
      "Epoch 3/10\n",
      " - 27s - loss: 106.2785 - acc: 0.5856 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 110.39398\n",
      "Epoch 4/10\n",
      " - 27s - loss: 106.2785 - acc: 0.5856 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 110.39398\n",
      "Epoch 5/10\n",
      " - 27s - loss: 106.2785 - acc: 0.5856 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 110.39398\n",
      "Epoch 6/10\n",
      " - 27s - loss: 106.2785 - acc: 0.5856 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 110.39398\n",
      "Epoch 7/10\n",
      " - 27s - loss: 106.2785 - acc: 0.5856 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 110.39398\n",
      "Epoch 8/10\n",
      " - 27s - loss: 106.2785 - acc: 0.5856 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 110.39398\n",
      "Epoch 9/10\n",
      " - 27s - loss: 106.2785 - acc: 0.5856 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 110.39398\n",
      "Epoch 10/10\n",
      " - 27s - loss: 106.2785 - acc: 0.5856 - val_loss: 110.3940 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 110.39398\n"
     ]
    }
   ],
   "source": [
    "if enable_pt16:\n",
    "    model_pt16 = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    if not disable_training:\n",
    "        print(\"Training P16\")\n",
    "        model_train(model=model_pt16, optimizer=optimizer, loss_function=perceptual_16_plus_texture_loss,\n",
    "                    checkpoint_path=checkpoint_path_pt16, verbose=training_verbose)\n",
    "    model_predict(model=model_pt16, checkpoint_path=checkpoint_path_pt16)\n",
    "    del model_pt16\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try some with bicubic interpolation included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peceptual loss 16 + texture loss. Bicubic interpolation included in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PT16_BCI\n",
      "Train on 600 samples, validate on 100 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[8,32,32,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node loss_6/add_71_loss/truediv_5-0-0-TransposeNCHWToNHWC-LayoutOptimizer}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](loss_6/add_71_loss/truediv_5, loss_6/add_71_loss/Mean-1-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss_6/mul/_7501}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3581_loss_6/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-f874424509af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training PT16_BCI\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         model_train(model=model_pt16_bci, optimizer=optimizer, loss_function=perceptual_16_plus_texture_loss,\n\u001b[1;32m----> 6\u001b[1;33m                     checkpoint_path=checkpoint_path_pt16_bci, verbose=training_verbose)\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mmodel_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_pt16_bci\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint_path_pt16_bci\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mmodel_pt16_bci\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-c16202c4ba8c>\u001b[0m in \u001b[0;36mmodel_train\u001b[1;34m(model, optimizer, loss_function, checkpoint_path, verbose)\u001b[0m\n\u001b[0;32m     12\u001b[0m     model.fit(train_data_tensors, train_truth_tensors,\n\u001b[0;32m     13\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_data_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_truth_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m               epochs=train_epochs, batch_size=train_batch_size, callbacks=[checkpointer, early_stopper], verbose=verbose)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[8,32,32,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node loss_6/add_71_loss/truediv_5-0-0-TransposeNCHWToNHWC-LayoutOptimizer}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](loss_6/add_71_loss/truediv_5, loss_6/add_71_loss/Mean-1-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss_6/mul/_7501}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3581_loss_6/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "if enable_pt16_bci:\n",
    "    model_pt16_bci = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=True)\n",
    "    if not disable_training:\n",
    "        print(\"Training PT16_BCI\")\n",
    "        model_train(model=model_pt16_bci, optimizer=optimizer, loss_function=perceptual_16_plus_texture_loss,\n",
    "                    checkpoint_path=checkpoint_path_pt16_bci, verbose=training_verbose)\n",
    "    model_predict(model=model_pt16_bci, checkpoint_path=checkpoint_path_pt16_bci)\n",
    "    del model_pt16_bci\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptual plus texture loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_pt_bci:\n",
    "    model_pt_bci = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=True)\n",
    "    if not disable_training:\n",
    "        print(\"Training PT_BCI\")\n",
    "        model_train(model=model_pt_bci, optimizer=optimizer, loss_function=perceptual_plus_texture_loss,\n",
    "                    checkpoint_path=checkpoint_path_pt_bci, verbose=training_verbose)\n",
    "    model_predict(model=model_pt_bci, checkpoint_path=checkpoint_path_pt_bci)\n",
    "    del model_pt_bci\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peceptual loss 16 + texture loss. No residual network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_pt16_no_res:\n",
    "    model_pt16_no_res = generator_no_residual(input_shape=train_data_shape, summary=False)\n",
    "    if not disable_training:\n",
    "        print(\"Training PT16_NO_RES\")\n",
    "        model_train(model=model_pt16_no_res, optimizer=optimizer,\n",
    "                    loss_function=perceptual_16_plus_texture_loss,\n",
    "                    checkpoint_path=checkpoint_path_pt16_no_res, verbose=training_verbose)\n",
    "    model_predict(model=model_pt16_no_res,\n",
    "                  checkpoint_path=checkpoint_path_pt16_no_res)\n",
    "    del model_pt16_no_res\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare all of the models at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_data = []\n",
    "\n",
    "if enable_p:\n",
    "    model_p = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    models_data.append({'name': \"P\", 'model': model_p, 'checkpoint': checkpint_path_p})\n",
    "\n",
    "if enable_p19:\n",
    "    model_p19 = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    models_data.append({'name': \"P VGG19\", 'model': model_p19, 'checkpoint': checkpoint_path_p19})\n",
    "\n",
    "if enable_p16:\n",
    "    model_p16 = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    models_data.append({'name': \"P VGG16\", 'model': model_p16, 'checkpoint': checkpoint_path_p16})\n",
    "\n",
    "if enable_t:\n",
    "    model_t = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    models_data.append({'name': \"T\", 'model': model_t, 'checkpoint': checkpoint_path_t})\n",
    "\n",
    "if enable_pt:\n",
    "    model_pt = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    models_data.append({'name': \"PT\", 'model': model_pt,\n",
    "                        'checkpoint': checkpoint_path_pt})\n",
    "\n",
    "if enable_pt16:\n",
    "    model_pt16 = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=False)\n",
    "    models_data.append({'name': \"PT VGG16\", 'model': model_pt16,\n",
    "                        'checkpoint': checkpoint_path_pt16})\n",
    "\n",
    "if enable_pt16_bci:\n",
    "    model_pt16_bci = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=True)\n",
    "    models_data.append({'name': \"PT VGG16 (BCI)\", 'model': model_pt16_bci,\n",
    "                        'checkpoint': checkpoint_path_pt16_bci})\n",
    "\n",
    "if enable_pt_bci:\n",
    "    model_pt_bci = generator_with_residual(input_shape=train_data_shape, summary=False, add_bicubic=True)\n",
    "    models_data.append({'name': \"PT (BCI)\", 'model': model_pt_bci,\n",
    "                        'checkpoint': checkpoint_path_pt_bci})\n",
    "\n",
    "if enable_pt16_no_res:\n",
    "    model_pt16_no_res = generator_no_residual(input_shape=train_data_shape, summary=False)\n",
    "    models_data.append({'name': \"PT VGG16 (NR)\", 'model': model_pt16_no_res,\n",
    "                        'checkpoint': checkpoint_path_pt16_no_res})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the images in higher dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models_single_image(test_data_tensors, test_truth_tensors, models_data, test_image_index_to_show, show_input=True, show_interpolated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
