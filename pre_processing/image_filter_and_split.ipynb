{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the passed input images and copy them to a common location. After that split them into train, validation and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from math import floor\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image_size_compliance(file_name, min_side=384):\n",
    "    try:\n",
    "        img = load_img(file_name)\n",
    "    except IOError:\n",
    "        return False\n",
    "\n",
    "    width, height = img.size\n",
    "    if width < min_side or height < min_side:\n",
    "        # print(\"Skipping image: \", file_name)\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_complian_images(folder_path, min_side=384):\n",
    "    compliant_images = []\n",
    "    for img_path in tqdm(glob(\"{0}/*\".format(folder_path))):\n",
    "        compliant = check_image_size_compliance(img_path, min_side)\n",
    "        if compliant:\n",
    "            compliant_images.append(img_path)\n",
    "\n",
    "    return compliant_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images_to_path(images_list, destination_path):\n",
    "    for file_path in tqdm(images_list):\n",
    "        shutil.copy2(file_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_copy_images_to_folder(input_folder, destination_folder, min_side=384):\n",
    "    print(\"Get valid images...\")\n",
    "    all_valid_images = get_size_complian_images(folder_path=input_folder, min_side=min_side)\n",
    "    print(\"Copy the valid images to destionation...\")\n",
    "    copy_images_to_path(images_list=all_valid_images, destination_path=destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_dataset_files(input_dataset):\n",
    "    return glob(\"{0}/*\".format(input_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(input_dataset_files, train_path, validation_path, test_path, train_ratio=0.75, validation_ratio=0.2, test_ratio=0.5):\n",
    "    images_count = len(input_dataset_files)\n",
    "    \n",
    "    random.shuffle(input_dataset_files)\n",
    "\n",
    "    train_start = 0\n",
    "    validation_start = int(images_count * train_ratio)\n",
    "    test_start = int(images_count * (train_ratio + validation_ratio))\n",
    "\n",
    "    train_images = input_dataset_files[0:validation_start]\n",
    "    validation_images = input_dataset_files[validation_start:test_start]\n",
    "    test_images = input_dataset_files[test_start:]\n",
    "\n",
    "    print('train_images: ', len(train_images))\n",
    "    print('validation_images: ', len(validation_images))\n",
    "    print('test_images: ', len(test_images))\n",
    "    print('Copying train images...')\n",
    "    \n",
    "    for file_path in tqdm(train_images):\n",
    "        shutil.copy2(file_path, train_path)\n",
    "\n",
    "    print('Copying validation images...')\n",
    "    for file_path in tqdm(validation_images):\n",
    "        shutil.copy2(file_path, validation_path)\n",
    "        \n",
    "    print('Copying test images...')\n",
    "    for file_path in tqdm(test_images):\n",
    "        shutil.copy2(file_path, test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter and merge the input images for MS COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset_paths = ['D:/datasets/images/mscoco/train2014', 'D:/datasets/images/mscoco/train2017',\n",
    "                       'D:/datasets/images/mscoco/val2014', 'D:/datasets/images/mscoco/val2017',\n",
    "                       'D:/datasets/images/mscoco/test2014', 'D:/datasets/images/mscoco/test2015', 'D:/datasets/images/mscoco/test2017']\n",
    "\n",
    "merged_dataset_path = 'D:/datasets/images/mscoco/merged'\n",
    "\n",
    "train_dataset_path = 'D:/git/image_super_resolution/data/MSCOCO/train'\n",
    "validation_dataset_path = 'D:/git/image_super_resolution/data/MSCOCO/val'\n",
    "test_dataset_path = 'D:/git/image_super_resolution/data/MSCOCO/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get valid images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 82783/82783 [03:11<00:00, 431.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy the valid images to destionation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 68382/68382 [08:15<00:00, 137.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get valid images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 118287/118287 [04:53<00:00, 402.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy the valid images to destionation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 97799/97799 [48:38<00:00, 33.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get valid images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 40504/40504 [01:58<00:00, 343.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy the valid images to destionation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 33489/33489 [10:17<00:00, 54.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get valid images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:32<00:00, 154.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy the valid images to destionation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4072/4072 [01:40<00:00, 40.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get valid images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 40775/40775 [02:07<00:00, 320.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy the valid images to destionation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 33694/33694 [15:21<00:00, 36.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get valid images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 81434/81434 [03:24<00:00, 398.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy the valid images to destionation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 67374/67374 [31:45<00:00, 35.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get valid images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 40670/40670 [01:49<00:00, 372.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy the valid images to destionation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 33508/33508 [15:03<00:00, 37.10it/s]\n"
     ]
    }
   ],
   "source": [
    "for folder in input_dataset_paths:\n",
    "    filter_and_copy_images_to_folder(folder, merged_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the images to the train, validation and test folders\n",
    "- 75% train\n",
    "- 20% validation\n",
    "- 5% test\n",
    "\n",
    "I picked only 5% for test since we are going to visualy inspect the images. If needed I can change the ratio.\n",
    "Even the validation set might be too big, since on the GAN we don't need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images:  253738\n",
      "validation_images:  67664\n",
      "test_images:  16916\n",
      "Copying train images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 253738/253738 [5:30:10<00:00, 12.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying validation images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 67664/67664 [1:03:08<00:00, 17.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying test images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 16916/16916 [15:30<00:00, 28.58it/s]\n"
     ]
    }
   ],
   "source": [
    "split_dataset(get_input_dataset_files(merged_dataset_path), train_dataset_path, validation_dataset_path, test_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter and split the images for CelebA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset_path = 'C:/datasets/img_celeba'\n",
    "\n",
    "train_dataset_path = 'C:/git/image_super_resolution/data/celeba/train'\n",
    "validation_dataset_path = 'C:/git/image_super_resolution/data/celeba/val'\n",
    "test_dataset_path = 'C:/git/image_super_resolution/data/celeba/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images:  202599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 202599/202599 [00:31<00:00, 6529.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of compliant images:  98102\n",
      "train_images:  73576\n",
      "validation_images:  19620\n",
      "test_images:  4906\n",
      "Copying train images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 73576/73576 [02:58<00:00, 412.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying validation images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 19620/19620 [01:12<00:00, 271.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying test images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4906/4906 [00:14<00:00, 346.05it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of images: \", len(glob(\"{0}/*\".format(merged_dataset_path))))\n",
    "print(\"Getting the list of compliant images...\")\n",
    "compliant_images = get_size_complian_images(merged_dataset_path)\n",
    "print(\"Number of compliant images: \", len(compliant_images))\n",
    "split_dataset(compliant_images, train_dataset_path, validation_dataset_path, test_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
